# -*- coding: utf-8 -*-
"""Copy of CNN_ClassifyMasopust.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hkcl_DUWo7M8bEhXMOydrRw5F3Np4-vP
"""

! pip install pydrive

import os
import numpy as np
import matplotlib.pyplot as plt
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from google.colab import files
from oauth2client.client import GoogleCredentials
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from keras.models import load_model
from sklearn.metrics import classification_report, confusion_matrix
from itertools import product

def copy_directory(source_id, local_target):
  try:
    os.makedirs(local_target)
  except: 
    pass
  k = 0
  print('folder id: %s' % (source_id))
  print('downloading to: %s' % (local_target)) 
  file_list = drive.ListFile(
    {'q': "'{source_id}' in parents".format(source_id=source_id)}).GetList()
  for f in file_list:
    if f["title"].startswith("."):
      continue
    fname = os.path.join(local_target, f['title'])
    if f['mimeType'] == 'application/vnd.google-apps.folder':
      copy_directory(f['id'], fname)
    else:
      f_ = drive.CreateFile({'id': f['id']})
      f_.GetContentFile(fname)
      k += 1
  print('downloaded files: {}'.format(k))

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.figure(figsize=(40,40)) 
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

training_path = os.path.expanduser('~/data/Training')
testing_path = os.path.expanduser('~/data/Testing')
prediction_path = os.path.expanduser('~/data/Prediction')
try:
  os.makedirs(training_path)
  os.makedirs(testing_path)
  os.makedirs(prediction_path)  
except: pass

copy_directory('1aM5XbStClMulA5CShCD9tfkYqAUjCCpX','~/data/Training')

copy_directory('1PVPjRT22MRPHkiyqCdEeKp3OGiaSUk_C','~/data/Testing')

copy_directory('1t7xxFxNW_O2WRYMsVKcxrQ6vYBIMd5yG','~/data/Prediction')

os.listdir('~/data')

num_epoch = 15

train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1. / 255)
training_set = train_datagen.flow_from_directory('~/data/Training', target_size=(64, 64), batch_size=32, class_mode='categorical')
test_set = test_datagen.flow_from_directory('~/data/Testing', target_size=(64, 64), batch_size=32, class_mode='categorical')

print(len(training_set.filenames))
indices = training_set.class_indices
print(indices)
print(len(test_set.class_indices))
print(len(test_set.filenames))
indices = test_set.class_indices
print(indices)
print(len(test_set.class_indices))

import matplotlib.pyplot as plt
plt.hist(training_set.classes, bins='auto')  # arguments are passed to np.histogram
plt.title("Histogram of training dataset")
plt.show()

import matplotlib.pyplot as plt
plt.hist(test_set.classes, bins='auto')  # arguments are passed to np.histogram
plt.title("Histogram of testing dataset")
plt.show()

classifier = Sequential()
classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Conv2D(32, (3, 3), activation = 'relu'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Flatten(input_shape=classifier.output_shape[1:]))
classifier.add(Dense(units = 256, activation = 'relu'))
classifier.add(Dropout(0.5))
classifier.add(Dense(units = 62, activation = 'softmax'))
classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

classifier.summary()
classifier.get_config()
classifier.layers[0].get_config()
classifier.layers[0].input_shape			
classifier.layers[0].output_shape			
classifier.layers[0].get_weights()
np.shape(classifier.layers[0].get_weights()[0])
classifier.layers[0].trainable

hist = classifier.fit_generator(training_set,steps_per_epoch = 4575, epochs = num_epoch, validation_data = test_set, validation_steps = 2520)
classifier.save('my_classifier_OK.h5')

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)
uploaded = drive.CreateFile()
uploaded.SetContentFile('my_classifier_OK.h5')
uploaded.Upload()

# visualizing losses and accuracy
train_loss=hist.history['loss']
val_loss=hist.history['val_loss']
train_acc=hist.history['acc']
val_acc=hist.history['val_acc']
xc=range(num_epoch)

plt.figure(1,figsize=(7,5))
plt.plot(xc,train_loss)
plt.plot(xc,val_loss)
plt.xlabel('num of Epochs')
plt.ylabel('loss')
plt.title('train_loss vs val_loss')
plt.grid(True)
plt.legend(['train','val'])
#print plt.style.available # use bmh, classic,ggplot for big pictures
plt.style.use(['classic'])

plt.figure(2,figsize=(7,5))
plt.plot(xc,train_acc)
plt.plot(xc,val_acc)
plt.xlabel('num of Epochs')
plt.ylabel('accuracy')
plt.title('train_acc vs val_acc')
plt.grid(True)
plt.legend(['train','val'],loc=4)
#print plt.style.available # use bmh, classic,ggplot for big pictures
plt.style.use(['classic'])

# Evaluating the model
score = classifier.evaluate_generator(test_set)
print('Test Loss:', score[0])
print('Test accuracy:', score[1])

model = load_model('my_classifier.h5')

test_image = image.load_img('~/data/Prediction/00017_00002.ppm', target_size = (64, 64))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = model.predict(test_image)
print(result)

#probabilities  = model.predict_generator(test_datagen, steps=None)
print(test_set)

test_set.reset()
probabilities  = model.predict_generator(test_set)
y_pred = np.argmax(probabilities , axis=1)


cnf_matrix = confusion_matrix(test_set.classes, y_pred)
plot_confusion_matrix(cnf_matrix, list(range(0, 62)), True)